{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head cell\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('mhrice.json') as file:\n",
    "    raw = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monster Names & IDs\n",
    "SECTIONS:\n",
    "- **monster_names**: rise english names\n",
    "- **monster_names_mr**: sunbreak english names\n",
    "- **monsters**: IDs\n",
    "- **random_mystery_enemy**: monster A★ and M★ rank numbers\n",
    "\n",
    "COLUMNS:\n",
    "- **id**: base monster id\n",
    "- **sub_id**: indicates monster variant\n",
    "- **em_id** (enemy_type): monster id when referenced by \"EnemyIndex###(_MR)\"\n",
    "- **em_type.Em**: internal monster identifier\n",
    "- **mon_name**: monster name\n",
    "- **normal_rank**: M★ rank. 12 indicates access through anomaly only.\n",
    "- **mystery_rank**: A★ rank. 12 indicates access as secondary target only.\n",
    "\n",
    "OUTPUT: **df_monsters**\n",
    "| id | sub_id | em_id | em_type.Em | mon_name | normal_rank | mystery_rank |\n",
    "|-|-|-|-|-|-|-|\n",
    "| 1 | 0 | 0 | 1 | Rathian | 2 | 3 |\n",
    "| 1 | 2 | 76 | 513 | Gold Rathian | 6 | 7 |\n",
    "| 1 | 7 | 1 | 1793 | Apex Rathian | 12 | 12 |\n",
    "| 2 | 0 | 2 | 2 | Rathalos | 4 | 5 |\n",
    "| 2 | 2 | 77 | 514 | Silver Rathalos | 6 | 7 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_entry = True #maintaints Toadversary and non-anomaly MR monsters in data\n",
    "\n",
    "# Monster Names\n",
    "sect = raw.get('monster_names').get('entries')\n",
    "df = pd.json_normalize(sect)\n",
    "df['mon_name'] = df['content'].apply(lambda x: x[1]) #grab only english name\n",
    "df['em_id'] = pd.to_numeric(df['name'].apply(lambda x: x[-3:])) #grab only id number\n",
    "df = df.iloc[0:46] #remove small monsters\n",
    "df_monster_names = df[['em_id', 'mon_name']].copy()\n",
    "\n",
    "# MR Monster Names\n",
    "sect = raw.get('monster_names_mr').get('entries')\n",
    "df = pd.json_normalize(sect)\n",
    "df['mon_name'] = df['content'].apply(lambda x: x[1])\n",
    "df['em_id'] = pd.to_numeric(df['name'].apply(lambda x: x[-6:-3]))\n",
    "df = pd.concat([df.iloc[0:23], df.iloc[31:]], axis=0, ignore_index=True)\n",
    "\n",
    "df_monster_names = pd.concat([df_monster_names, df[['em_id', 'mon_name']]], axis=0, ignore_index=True)\n",
    "\n",
    "# Monster IDs\n",
    "sect = raw.get('monsters')\n",
    "df = pd.json_normalize(sect)\n",
    "df = df[['id','sub_id','enemy_type','em_type.Em']]\n",
    "df.rename(columns={'enemy_type':'em_id'}, inplace=True)\n",
    "\n",
    "df_monsters = pd.merge(df,df_monster_names, on='em_id', how='left')\n",
    "\n",
    "if manual_entry:\n",
    "    df_monsters.loc[df_monsters['em_id'] == 46, 'mon_name'] = 'Toadversary' # add Toadversary to list\n",
    "else:\n",
    "    df_monsters.dropna(subset=['mon_name'], inplace=True) # drop Toadversary from list\n",
    "    df_monsters.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Anomaly Data\n",
    "sect = raw.get('random_mystery_enemy').get('lot_enemy_list')\n",
    "df = pd.json_normalize(sect)\n",
    "df = df[['em_type.Em','normal_rank','mystery_rank']]\n",
    "\n",
    "df_monsters = pd.merge(df_monsters,df, on='em_type.Em', how='left')\n",
    "\n",
    "if manual_entry:\n",
    "    df_monsters.loc[df_monsters['mon_name'] == 'Amatsu', 'normal_rank'] = 6\n",
    "    df_monsters.loc[df_monsters['mon_name'] == 'Wind Serpent Ibushi', 'normal_rank'] = 6\n",
    "    df_monsters.loc[df_monsters['mon_name'] == 'Thunder Serpent Narwa', 'normal_rank'] = -1\n",
    "    df_monsters.loc[df_monsters['mon_name'] == 'Narwa the Allmother', 'normal_rank'] = 6\n",
    "    df_monsters.loc[df_monsters['mon_name'] == 'Gaismagorm', 'normal_rank'] = 6\n",
    "else:\n",
    "    df_monsters.dropna(subset=['mystery_rank'], inplace=True)\n",
    "    df_monsters.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_monsters.fillna(-1, inplace=True)\n",
    "df_monsters[['normal_rank','mystery_rank']] = df_monsters[['normal_rank','mystery_rank']].astype(int)\n",
    "\n",
    "# df_monsters.to_excel('monster.xlsx')\n",
    "# print(df_monsters[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Names, IDs, & Properties\n",
    "SECTIONS:\n",
    "- **items_name_msg**: rise english names & ids\n",
    "- **items_name_msg_mr**: sunbreak english names & ids\n",
    "- **items**: item properties\n",
    "\n",
    "OUTPUT: **df_items**\n",
    "| item_id | item_name | type_ | category_prefix | material_category | category_worth | rare |\n",
    "|-|-|-|-|-|-|-|\n",
    "| 6 | Potion | Consume | 'None' | [] | 0 | 1 |\n",
    "| 7 | Mega Potion | Consume | 'None' | [] | 0 | 2 |\n",
    "| 5 | Max Potion | Consume | 'None' | [] | 0 | 3 |\n",
    "| 467 | Ancient Potion | Consume | 'None' | [] | 0 | 4 |\n",
    "| 13 | Antidote | Consume | 'None' | [] | 0 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item Names & IDs\n",
    "sect = raw.get('items_name_msg').get('entries')\n",
    "df = pd.json_normalize(sect)\n",
    "df.rename(columns={'name':'item_id'}, inplace=True)\n",
    "df=df[~df['item_id'].str.contains('I_EC_')] # remove endemic life\n",
    "df['item_id'] = df['item_id'].str.extract('(\\d+)', expand=False) # grab only item number\n",
    "df.dropna(inplace=True) # drop blanks\n",
    "df['item_id'] = pd.to_numeric(df['item_id'], errors='coerce', downcast='integer') # convert column to int\n",
    "df['item_name'] = df['content'].apply(lambda x: x[1]) # grab only english name\n",
    "df = df[~df['item_name'].str.contains('COLOR FF0000', na=False)] # remove placeholder items\n",
    "df_item_names = df[['item_id', 'item_name']].copy()\n",
    "\n",
    "# MR Item Names & IDs\n",
    "sect = raw.get('items_name_msg_mr').get('entries')\n",
    "df = pd.json_normalize(sect)\n",
    "df.rename(columns={'name':'item_id'}, inplace=True)\n",
    "df=df[~df['item_id'].str.contains('I_EC_')]\n",
    "df['item_id'] = df['item_id'].str.extract('(\\d+)', expand=False)\n",
    "df.dropna(inplace=True)\n",
    "df['item_id'] = pd.to_numeric(df['item_id'], errors='coerce', downcast='integer')\n",
    "df['item_name'] = df['content'].apply(lambda x: x[1])\n",
    "df = df[~df['item_name'].str.contains('COLOR FF0000', na=False)]\n",
    "\n",
    "df_item_names = pd.concat((df_item_names, df[['item_id', 'item_name']]), axis=0, ignore_index=True)\n",
    "\n",
    "# Item Types, Categories, Worth, and Rarity\n",
    "sect = raw.get('items').get('param')\n",
    "df = pd.json_normalize(sect)\n",
    "df.rename(columns={'id.Normal':'item_id'}, inplace=True)\n",
    "df = df[['item_id', 'type_', 'material_category', 'category_worth', 'rare']]\n",
    "df = pd.merge(df, df_item_names, on='item_id', how='left')\n",
    "df.dropna(subset=['item_name'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Denesting Category Dictionary\n",
    "df['category_prefix'] = df['material_category'].apply(lambda x: next(iter(x[0])) if isinstance(x[0],dict) else x[0]) # prefix\n",
    "df['material_category'] = df['material_category'].apply(lambda x: [d for d in x if isinstance(d, dict)]) # None removal\n",
    "df['material_category'] = df['material_category'].apply(lambda x: [list(d.values())[0] for d in x] if x else []) # denest\n",
    "\n",
    "df_items = df[['item_id', 'item_name', 'type_', 'category_prefix', 'material_category', 'category_worth', 'rare']].copy()\n",
    "\n",
    "# print(df_items.head(5))\n",
    "# df_items.to_excel('items.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Tables\n",
    "SECTIONS:\n",
    "- **reward_id_lot_table**: base game item drop chance and count tables\n",
    "- **reward_id_lot_table_mr**: sunbreak item drop chance and count tables\n",
    "\n",
    "OUTPUT: **df_drop_tables**\n",
    "| drop_table_id | lot_rule | item_id_list | num_list | probability_list |\n",
    "|-|-|-|-|-|\n",
    "| 310000 | Random | [125, 126, 687, 128, 699, 131, 719] | [1, 1, 1, 2, 1, 1, 1] | [17, 24, 15, 22, 8, 8, 6] |\n",
    "| 310001 | Random | [691, 132, 720, 705, 704, 129, 700] | [1, 1, 1, 1, 1, 1, 1] | [9, 14, 7, 19, 25, 14, 12] |\n",
    "| 310002 | Random | [693, 133, 710, 706, 707, 688, 701] | [1, 1, 1, 1, 1, 1, 1] | [5, 11, 16, 18, 14, 21, 15] |\n",
    "| 310003 | Random | [702, 484, 686, 689, 127, 133, 721] | [2, 1, 1, 1, 1, 1, 1] | [18, 17, 23, 14, 9, 13, 6] |\n",
    "| 310004 | Random | [695, 134, 479, 711, 690, 718, 127] | [1, 1, 1, 1, 1, 1, 1] | [5, 9, 19, 19, 14, 23, 11] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item Drop Tables\n",
    "sect = raw.get('reward_id_lot_table').get('param')\n",
    "df = pd.json_normalize(sect)\n",
    "df['item_id_list'] = df['item_id_list'].apply(lambda y: [x[\"Normal\"] for x in y if isinstance(x,dict)])\n",
    "df['num_list'] = df['num_list'].apply(lambda y: [x for x in y if x>0])\n",
    "df['probability_list'] = df['probability_list'].apply(lambda y: [x for x in y if x>0])\n",
    "df_drop_tables = df.copy()\n",
    "\n",
    "# MR Item Drop Tables\n",
    "sect = raw.get('reward_id_lot_table_mr').get('param')\n",
    "df = pd.json_normalize(sect)\n",
    "df['item_id_list'] = df['item_id_list'].apply(lambda y: [x[\"Normal\"] for x in y if isinstance(x,dict)])\n",
    "df['num_list'] = df['num_list'].apply(lambda y: [x for x in y if x>0])\n",
    "df['probability_list'] = df['probability_list'].apply(lambda y: [x for x in y if x>0])\n",
    "df_drop_tables = pd.concat([df_drop_tables, df], axis=0, ignore_index=True)\n",
    "df_drop_tables.rename(columns={'id':'drop_table_id'}, inplace=True)\n",
    "\n",
    "# df_drop_tables.to_excel('item_drop_tables.xlsx')\n",
    "# print(df_drop_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Items, Subset of Items\n",
    "\n",
    "COLUMNS:\n",
    "- **item_id**: item ID\n",
    "- **item_name**: item name\n",
    "- **type**: material type [aff, ess, coin]\n",
    "- **category_worth**: item value in augmenting and charm melding\n",
    "\n",
    "OUTPUT: **df_anomaly_items**\n",
    "| item_id | item_name | type | category_worth |\n",
    "|-|-|-|-|\n",
    "| 2521 | Amber Essence | ess | 10 |\n",
    "| 2522 | Amber Essence+ | ess | 20 |\n",
    "| 2523 | Prime Amber Essence | ess | 40 |\n",
    "| 2584 | Afflicted Bone | aff | 2 |\n",
    "| 2585| Afflicted Pelt | aff | 2 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_items[~df_items['category_prefix'].str.contains('LrHr')] #remove LrHr items so that only Mr or None results show\n",
    "df_anomaly_items = df[df['material_category'].apply(lambda x: 73 in x)].copy()\n",
    "df_anomaly_items['type'] = 'aff'\n",
    "df_ess = df[df['material_category'].apply(lambda x: 74 in x)].copy()\n",
    "df_ess['type'] = 'ess'\n",
    "df_coin = df_items[df_items['item_name'].str.contains('Investigation Coin',case=False,na=False)].copy()\n",
    "df_coin['type'] = 'coin'\n",
    "df_anomaly_items = pd.concat([df_anomaly_items, df_ess, df_coin], axis=0, ignore_index=True)\n",
    "df_anomaly_items = df_anomaly_items[['item_id','item_name','type','category_worth']]\n",
    "df_anomaly_items.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# df_anomaly_items.to_excel('anom_items.xlsx')\n",
    "# print(df_anomaly_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Drop Lots\n",
    "SECTIONS:\n",
    "- **mystery_reward_item**: anomaly drop lots for quests, investigations, and special investigations\n",
    "\n",
    "COLUMNS:\n",
    "- **lv_lower** (~~lv_lower_limit~~): Anomaly investigation reward bracket lower level. 0 for quests. 300 for special investigations.\n",
    "- **lv_upper** (~~lv_upper_limit~~): Anomaly investigation reward bracket upper level. 0 for quests. 300 for special investigations.\n",
    "- **em_type.Em**: primary target monster internal ID\n",
    "- **item_id** (~~reward_item.Normal~~): the primary afflicted material dropped by primary target monster on carve and part break\n",
    "- **anom_item_chance** (~~hagibui_probability~~): chance of getting primary afflicted material on carve and part break\n",
    "- **anom_drop_table_id** (~~quest_reward_table_index~~): table ID for quest rewards.\n",
    "- **anom_drop_lot_ids** (~~additional_quest_reward_table_index~~): additional quest reward table IDs.\n",
    "- **sp_ess_table_id** (~~special_quest_reward_table_index~~): bonus essence drop table for single AR brackets (e.g. AR200, AR220)\n",
    "- **multi_ess_table_id** (~~multiple_target_reward_table_index~~): bonus essence drop table for hunting monster as secondary target\n",
    "- **multi_coin_table_id**: (~~multiple_fix_reward_table_index~~): bonus coin drop table for hunting monster as secondary target\n",
    "- **mystery_reward_table**: ???\n",
    "\n",
    "OUTPUT: **df_anom_drop_lots**\n",
    "| lv_lower | lv_upper | anom_item_chance | anom_drop_table_id | anom_drop_lot_ids |\n",
    "|-|-|-|-|-|\n",
    "| 0 | 0 | 40 | 0 | [0, 0, 0, 0] |\n",
    "| 1 | 30 | 40 | 560000 | [550000, 540000, 0, 330300] |\n",
    "| 31 | 50 | 40 | 560000 | [550100, 540001, 550000, 330300] |\n",
    "| 51 | 70 | 40 | 560001 | [550100, 540100, 550000, 330300] |\n",
    "| 71 | 90 | 40 | 560001 | [550101, 540100, 550000, 330301] |\n",
    "\n",
    "| sp_ess_table_id | multi_ess_table_id | multi_coin_table_id | em_type.Em | item_id |\n",
    "|-|-|-|-|-|\n",
    "| 0 | 0 | 0 | 98 | 2585 |\n",
    "| 0 | 760000 | 770000 | 98 | 2585 |\n",
    "| 0 | 760000 | 770000 | 98 | 2885 |\n",
    "| 0 | 760001 | 770001 | 98 | 2885 |\n",
    "| 0 | 760001 | 770001 | 98 | 2885 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly Drop Lots\n",
    "sect = raw.get('mystery_reward_item').get('param')\n",
    "df = pd.json_normalize(sect)\n",
    "df = df[df['is_special_mystery']==False] # remove SI entries since drops are the same as AR300 and represented separately in [300,300] investigations\n",
    "df = df[~((df['lv_lower_limit']==0) & (df['lv_upper_limit']==0))] # remove 0-0 entries as they don't represent anomaly quest rewards\n",
    "\n",
    "df['reward_item.Normal'] = pd.to_numeric(df['reward_item.Normal'].fillna(-1), errors='ignore', downcast='integer')\n",
    "df.drop(['is_special_mystery','quest_no', 'item_num', 'reward_item', 'mystery_reward_table'], axis=1, inplace=True)\n",
    "\n",
    "df.rename(columns={'lv_lower_limit':'lv_lower',\n",
    "           'lv_upper_limit':'lv_upper',\n",
    "           'reward_item.Normal':'item_id',\n",
    "           'hagibui_probability':'anom_item_chance',\n",
    "           'quest_reward_table_index':'anom_drop_table_id',\n",
    "           'additional_quest_reward_table_index':'anom_drop_lot_ids',\n",
    "           'special_quest_reward_table_index':'sp_ess_table_id',\n",
    "           'multiple_target_reward_table_index':'multi_ess_table_id',\n",
    "           'multiple_fix_reward_table_index':'multi_coin_table_id'\n",
    "           },inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_anom_drop_lots = df.copy()\n",
    "# print(df_anom_drop_lots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Material Average Item Drop\n",
    "\n",
    "REFERENCES:\n",
    "- **df_anomaly_items**\n",
    "- **df_drop_tables**\n",
    "\n",
    "COLUMNS:\n",
    "- **drop_table_id**: drop table ID\n",
    "- **aff_avg**: average afflicted material melding worth\n",
    "- **ess_avg**: average essence augmenting worth\n",
    "- **coin_avg**: average investigation coin worth\n",
    "\n",
    "OUTPUT: **df_anom_drop_avg**\n",
    "| drop_table_id | aff_avg | ess_avg | coin_avg |\n",
    "|-|-|-|-|\n",
    "| 530000 | 4.8 | 0.0 | 0.0 |\n",
    "| 530001 | 4.8 | 0.0 | 0.0 |\n",
    "| 530002 | 9.6 | 0.0 | 0.0 |\n",
    "| 530003 | 9.6 | 0.0 | 0.0 |\n",
    "| 530004 | 14.4 | 0.0 | 0.0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out non-anomaly drop tables\n",
    "mapper = set(df_anomaly_items['item_id'])\n",
    "df = df_drop_tables[df_drop_tables['item_id_list'].apply(lambda x: any(y in mapper for y in x))]\n",
    "\n",
    "#add translated names to items\n",
    "# mapper = dict(zip(df_items['item_id'], df_items['item_name']))\n",
    "# df_drop_tables['tab']=df_drop_tables['item_id_list'].apply(lambda x: [mapper.get(i,'?') for i in x])\n",
    "\n",
    "# translate item_id_list into worth_list\n",
    "df2 = df_anomaly_items[df_anomaly_items['type']=='aff']\n",
    "mapper = dict(zip(df2['item_id'], df2['category_worth']))\n",
    "df['aff_worth_list'] = df['item_id_list'].apply(lambda x: [mapper.get(i,0) for i in x])\n",
    "df2 = df_anomaly_items[df_anomaly_items['type']=='ess']\n",
    "mapper = dict(zip(df2['item_id'], df2['category_worth']))\n",
    "df['ess_worth_list'] = df['item_id_list'].apply(lambda x: [mapper.get(i,0) for i in x])\n",
    "df2 = df_anomaly_items[df_anomaly_items['type']=='coin']\n",
    "mapper = dict(zip(df2['item_id'], [1]))\n",
    "df['coin_worth_list'] = df['item_id_list'].apply(lambda x: [mapper.get(i,0) for i in x])\n",
    "\n",
    "# sum of products: item_cts, item_chance, aff_worth\n",
    "df['aff_avg'] = df.apply(lambda x: round(np.sum(np.array(x['num_list']) * np.array(x['probability_list']) * np.array(x['aff_worth_list']) /100),2), axis=1)\n",
    "df['ess_avg'] = df.apply(lambda x: round(np.sum(np.array(x['num_list']) * np.array(x['probability_list']) * np.array(x['ess_worth_list']) /100),2), axis=1)\n",
    "df['coin_avg'] = df.apply(lambda x: round(np.sum(np.array(x['num_list']) * np.array(x['probability_list']) * np.array(x['coin_worth_list']) /100),2), axis=1)\n",
    "\n",
    "df_anom_drop_avg = df[['drop_table_id','aff_avg','ess_avg','coin_avg']].copy()\n",
    "\n",
    "# df_anom_drop_avg['am_avg'] = df_anom_drop_avg.apply(lambda x: [x['aff_avg'], x['ess_avg'], x['coin_avg']], axis=1)\n",
    "# df_anom_drop_avg = df[['drop_table_id','am_avg']]\n",
    "\n",
    "# df_anom_drop_avg.to_excel('anom_drop_avg.xlsx')\n",
    "# print(df_anom_drop_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Material Drop Per Anomaly Investigation Level Bracket\n",
    "REFERENCES:\n",
    "- **df_anom_drop_lots**\n",
    "- **df_anomaly_items**\n",
    "- **df_anom_drop_avg**\n",
    "- **df_monsters**\n",
    "\n",
    "COLUMNS:\n",
    "- **lv_lower**: anomaly investigation level bracket lower end\n",
    "- **lv_upper**: anomaly investigation level bracket upper end\n",
    "- **item_name**: primary afflicted material reward\n",
    "- **aff_avg**: average afflicted material augment and melding value\n",
    "- **ess_avg**: average essence augment value\n",
    "- **coin_avg**: average investigation coin value\n",
    "- **ess_avg_multi**: average essence augment value for multi-monster investigations\n",
    "- **coin_avg_multi**: average investigation coin value for multi-monster investigations\n",
    "- **mon_name**: primary target name\n",
    "- **mystery_rank**: primary target rank\n",
    "\n",
    "OUTPUT: **df_anom_avg**\n",
    "| lv_lower | lv_upper | item_name | aff_avg | ess_avg | coin_avg | ess_avg_multi | coin_avg_multi | mon_name | mystery_rank |\n",
    "|-|-|-|-|-|-|-|-|-|-|\n",
    "| 1 | 30 | Afflicted Pelt | 7.2 | 56.5 | 0.05 | 29 | 2 | Great Izuchi | 1 |\n",
    "| 31 | 50 | Afflicted Hide+ | 29.6 | 67.5 | 0.05 | 29 | 2 | Great Izuchi | 1 |\n",
    "| 51 | 70 | Afflicted Hide+ | 29.6 | 115 | 0.25 | 58 | 2.4 | Great Izuchi | 1 |\n",
    "| 71 | 90 | Afflicted Hide+ | 38.4 | 115 | 0.25 | 58 | 2.4 | Great Izuchi | 1 |\n",
    "| 91 | 100 | Afflicted Hide+ | 63.8 | 289 | 0.25 | 84 | 2.4 | Great Izuchi | 1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carves = 4 # number of carves + estimated partbreaks\n",
    "df = df_anom_drop_lots\n",
    "\n",
    "#replace item_id with item name and worth from df_anomaly_items\n",
    "df = pd.merge(df, df_anomaly_items[['item_id','item_name','category_worth']], on='item_id', how='left')\n",
    "df.drop(columns=['item_id'], inplace=True)\n",
    "df.fillna(0,inplace=True)\n",
    "\n",
    "# #create carve reward worth column\n",
    "df['carve_worth'] = df.apply(lambda x: round(x['category_worth']*x['anom_item_chance']*carves/100,2), axis=1)\n",
    "df.drop(columns=['category_worth','anom_item_chance'], inplace=True)\n",
    "\n",
    "# #replace reward tables with am, ess, coin worth averages\n",
    "df = pd.merge(left=df, left_on='anom_drop_table_id', right=df_anom_drop_avg, right_on='drop_table_id', how='left')\n",
    "df.drop(columns=['anom_drop_table_id','drop_table_id'], inplace=True)\n",
    "df.fillna(0,inplace=True)\n",
    "# df = df.rename(columns={'am_avg':'quest_rewards'})\n",
    "df['aff_avg'] = df['aff_avg']+df['carve_worth']\n",
    "df.drop(columns='carve_worth', inplace=True)\n",
    "\n",
    "#replace additional quest rewards with am worth averages\n",
    "mapper = dict(zip(df_anom_drop_avg['drop_table_id'], list(zip(df_anom_drop_avg['aff_avg'],df_anom_drop_avg['ess_avg'],df_anom_drop_avg['coin_avg']))))\n",
    "df['aqr'] = df['anom_drop_lot_ids'].apply(lambda x: [mapper.get(i,[0,0,0]) for i in x])\n",
    "#zip addition quest rewards\n",
    "df['aqr_sum'] = df['aqr'].apply(lambda x: [round(sum(i),2) for i in zip(*x)])\n",
    "df.drop(columns=['aqr','anom_drop_lot_ids'], inplace=True)\n",
    "#individual column sum\n",
    "df['aff_avg'] = df.apply(lambda x: x['aff_avg']+x['aqr_sum'][0], axis=1)\n",
    "df['ess_avg'] = df.apply(lambda x: x['ess_avg']+x['aqr_sum'][1], axis=1)\n",
    "df['coin_avg'] = df.apply(lambda x: x['coin_avg']+x['aqr_sum'][2], axis=1)\n",
    "df.drop(columns='aqr_sum', inplace=True)\n",
    "\n",
    "#sp essence rewards\n",
    "df = pd.merge(left=df, left_on='sp_ess_table_id', right=df_anom_drop_avg[['drop_table_id','ess_avg']], right_on='drop_table_id', how='left', suffixes=['','_sp'])\n",
    "df.fillna(0,inplace=True)\n",
    "df['ess_avg'] = df['ess_avg']+df['ess_avg_sp']\n",
    "df.drop(columns=['drop_table_id','ess_avg_sp','sp_ess_table_id'], inplace=True)\n",
    "\n",
    "#multi rewards\n",
    "df = pd.merge(left=df, left_on='multi_ess_table_id', right=df_anom_drop_avg[['drop_table_id','ess_avg']], right_on='drop_table_id', how='left', suffixes=['','_multi'])\n",
    "df.fillna(0,inplace=True)\n",
    "df.drop(columns=['multi_ess_table_id','drop_table_id'], inplace=True)\n",
    "df = pd.merge(left=df, left_on='multi_coin_table_id', right=df_anom_drop_avg[['drop_table_id','coin_avg']], right_on='drop_table_id', how='left', suffixes=['','_multi'])\n",
    "df.fillna(0,inplace=True)\n",
    "df.drop(columns=['multi_coin_table_id','drop_table_id'], inplace=True)\n",
    "\n",
    "#monster names\n",
    "df = pd.merge(df, df_monsters[['em_type.Em','mon_name','mystery_rank']], on='em_type.Em',how='left')\n",
    "df.drop(columns=['em_type.Em'], inplace=True)\n",
    "\n",
    "df_anom_avg = df.copy()\n",
    "# df_anom_avg.to_excel('anom_avg.xlsx')\n",
    "# print(df_anom_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armor Skill Name & ID\n",
    "\n",
    "player_skill_name_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill Names & IDs\n",
    "sect = raw.get('player_skill_name_msg').get('entries')\n",
    "df = pd.json_normalize(sect)\n",
    "df['skill_name'] = df['content'].apply(lambda x: x[1]) #grab only english name\n",
    "df['skill_id'] = df['name'].str.extract('(\\d+)', expand=False) # grab id numbers\n",
    "df = df[df['skill_name']!=''] # remove blank names\n",
    "df.dropna(inplace=True) # remove blank ids\n",
    "df['skill_id'] = pd.to_numeric(df['skill_id'], errors='ignore', downcast='integer')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_skill_names = df[['skill_id', 'skill_name']].copy()\n",
    "\n",
    "# MR Skill Names & IDs\n",
    "sect = raw.get('player_skill_name_msg_mr').get('entries')\n",
    "df = pd.json_normalize(sect)\n",
    "df['skill_name'] = df['content'].apply(lambda x: x[1]) #grab only english name\n",
    "df['skill_id'] = df['name'].str.extract('(\\d+)', expand=False) # grab id numbers\n",
    "df = df[df['skill_name']!=''] # remove blank names\n",
    "df.dropna(inplace=True) # remove blank ids\n",
    "df['skill_id'] = pd.to_numeric(df['skill_id'], errors='ignore', downcast='integer')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_skill_names = pd.concat([df_skill_names, df[['skill_id', 'skill_name']]], axis=0, ignore_index=True)\n",
    "\n",
    "# print(df_skill_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decorations\n",
    "### \"decorations\": param\n",
    "- **decorations**: \"id\":{\"Deco\": 11}\n",
    "- **decoration_lv**: 2\n",
    "- **skill_id_list**: [{\"Skill\": 11},\"None\"]\n",
    "- **skill_lv_list**: [1,0]\n",
    "\n",
    "### \"decorations_product\": param\n",
    "- **id**: {\"Deco\": 0}\n",
    "- **item_flag**: \"None\"\n",
    "- **enemy_flag**: {\"Em\": 99}\n",
    "- **progress_flag**: 0\n",
    "- **item_id_list**: [{\"Normal\": 1036},\n",
    "                     {\"Normal\": 337},\n",
    "                     {\"Normal\": 571},\n",
    "                     {\"Normal\": 179}]\n",
    "- **item_num_list**: [5,3,3,1]\n",
    "\n",
    "### \"decorations_name_msg\":entries\n",
    "- **name**: \"Decorations_000_Name\n",
    "- **content**: [\"...\", \"Attack Jewel 2\", \"...\"]\n",
    "\n",
    "### \"decorations_name_msg_mr\":entries\n",
    "- **name**: \"Decorations_201_Name\n",
    "- **content**: [\"...\", \"Hard Fire Res Jewel 4\", \"...\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoration Names\n",
    "sect = raw.get('decorations_name_msg').get('entries')\n",
    "df = pd.json_normalize(sect)\n",
    "df['deco_name'] = df['content'].apply(lambda x: x[1]) #grab only english name\n",
    "df['deco_id'] = df['name'].str.extract('(\\d+)', expand=False) # grab id numbers\n",
    "df = df[df['deco_name']!=''] # remove blank names\n",
    "df.dropna(inplace=True) # remove blank ids\n",
    "df['deco_id'] = pd.to_numeric(df['deco_id'], errors='ignore', downcast='integer')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_deco_names = df[['deco_id', 'deco_name']].copy()\n",
    "\n",
    "# MR Decoration Names\n",
    "sect = raw.get('decorations_name_msg_mr').get('entries')\n",
    "df = pd.json_normalize(sect)\n",
    "df['deco_name'] = df['content'].apply(lambda x: x[1]) #grab only english name\n",
    "df['deco_id'] = df['name'].str.extract('(\\d+)', expand=False) # grab id numbers\n",
    "df = df[df['deco_name']!=''] # remove blank names\n",
    "df = df[~df['deco_name'].str.contains('COLOR FF0000', na=False)]\n",
    "df.dropna(inplace=True) # remove blank ids\n",
    "df['deco_id'] = pd.to_numeric(df['deco_id'], errors='ignore', downcast='integer')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_deco_names = pd.concat([df_deco_names, df[['deco_id', 'deco_name']]], axis=0, ignore_index=True)\n",
    "\n",
    "# Decoration Skills\n",
    "sect = raw.get('decorations').get('param')\n",
    "df = pd.json_normalize(sect)\n",
    "df['skill_grade'] = df['skill_id_list'].apply(lambda x: next(iter(x[0]))) # grab MR category\n",
    "df['skill_id'] = df['skill_id_list'].apply(lambda x: next(iter(x[0].values()))) # grab skill ID\n",
    "df.loc[df['skill_grade']=='MrSkill', 'skill_id'] += 200 # convert skill ID to +200 for MR\n",
    "df['id.Deco'] = df['id.Deco'].fillna(df['id.MrDeco']+200) # merge MrDeco ID into Deco IDs\n",
    "df.rename(columns={'id.Deco':'deco_id',\n",
    "                   'decoration_lv':'deco_size'}, inplace=True)\n",
    "df_deco_skills = df[['deco_id','deco_size','skill_id']].copy()\n",
    "\n",
    "# Decoration Unlock Conditions\n",
    "sect = raw.get('decorations_product').get('param')\n",
    "df = pd.json_normalize(sect)\n",
    "df['item_id_list'] = df['item_id_list'].apply(lambda y: [x[\"Normal\"] for x in y if isinstance(x,dict)])\n",
    "df['item_num_list'] = df['item_num_list'].apply(lambda y: [x for x in y if x>0])\n",
    "df['id.Deco'] = df['id.Deco'].fillna(df['id.MrDeco']+200) # merge MrDeco ID into Deco IDs\n",
    "df['item_flag.Normal'] = df['item_flag.Normal'].fillna(-1)\n",
    "df.rename(columns={'id.Deco':'deco_id',\n",
    "                   'enemy_flag.Em':'key_em_type.Em',\n",
    "                   'item_flag.Normal':'key_item_id',\n",
    "                   'item_id_list':'craft_item_id_list',\n",
    "                   'item_num_list':'craft_num_list'}, inplace=True)\n",
    "df_deco_flags = df[['deco_id','craft_item_id_list','craft_num_list','progress_flag','key_em_type.Em','key_item_id']].copy()\n",
    "df_deco_flags['deco_id'] = pd.to_numeric(df_deco_flags['deco_id'], errors='ignore', downcast='integer')\n",
    "df_deco_flags['key_item_id'] = pd.to_numeric(df_deco_flags['key_item_id'], errors='ignore', downcast='integer')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Bring it together\n",
    "# df_decos = pd.merge()\n",
    "\n",
    "# print(df_deco_flags)\n",
    "# print(df_decos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress Flags\n",
    "sect = raw.get('progress').get('param_list')\n",
    "df = pd.json_normalize(sect)\n",
    "df.fillna(-1)\n",
    "df_progress_flags = df[['progress_flag',\n",
    "                        'quest_no',\n",
    "                        'enable_progress_hr_check',\n",
    "                        'progress_hr',\n",
    "                        'village.VillageProgress',\n",
    "                        'hall.HallProgress',\n",
    "                        'mr.MasterRankProgress']].copy() # currently ignoring talk flags\n",
    "\n",
    "print(df_progress_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quest Lists\n",
    "q_sects = ['quest_arena_msg',\n",
    "           'quest_dlc_msg',\n",
    "           'quest_hall_msg',\n",
    "           'quest_hall_msg_mr',\n",
    "           'quest_hall_msg_mr2',\n",
    "           'quest_tutorial_msg',\n",
    "           'quest_village_msg',\n",
    "           'npc_mission_msg',\n",
    "           'npc_mission_msg_mr']\n",
    "df_quest_names = pd.DataFrame()\n",
    "for q in q_sects:\n",
    "    sect = raw.get(q).get('entries')\n",
    "    df = pd.json_normalize(sect)\n",
    "    df = df[df['name'].str.contains('_01')]\n",
    "    df['quest_type'] = df['name'].str.extract('(^[A-Za-z]+)')\n",
    "    df['quest_id'] = df['name'].str.extract('(\\d+)')\n",
    "    df['quest_id'] = pd.to_numeric(df['quest_id'],errors='coerce',downcast='integer')\n",
    "    df['content'] = df['content'].apply(lambda x: x[1])\n",
    "    df = df[~df['content'].str.contains('COLOR FF0000', na=False)]\n",
    "    df_quest_names = pd.concat([df_quest_names,df[['quest_id','quest_type','content']]], axis=0,ignore_index=True)\n",
    "df_quest_names = df_quest_names[df_quest_names['quest_type']!='QNmystery']\n",
    "# print(df_quest_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_deco_flags\n",
    "df = pd.merge(left=df, left_on='progress_flag', right=df_progress_flags, right_on='progress_flag', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''Gathering Node Drop Tables'''\n",
    "# sect = raw.get('item_pop_lot').get('param')\n",
    "# df = pd.json_normalize(sect)\n",
    "# df['lower_item_ids'] = df['lower_id'].apply(lambda y: [x[\"Normal\"] for x in y if isinstance(x,dict)])\n",
    "# df['lower_item_ct'] = df['lower_num'].apply(lambda y: [x for x in y if x>0])\n",
    "# df['lower_item_chance'] = df['lower_probability'].apply(lambda y: [x for x in y if x>0])\n",
    "# df['upper_item_ids'] = df['upper_id'].apply(lambda y: [x[\"Normal\"] for x in y if isinstance(x,dict)])\n",
    "# df['upper_item_ct'] = df['upper_num'].apply(lambda y: [x for x in y if x>0])\n",
    "# df['upper_item_chance'] = df['upper_probability'].apply(lambda y: [x for x in y if x>0])\n",
    "# df['master_item_ids'] = df['master_id'].apply(lambda y: [x[\"Normal\"] for x in y if isinstance(x,dict)])\n",
    "# df['master_item_ct'] = df['master_num'].apply(lambda y: [x for x in y if x>0])\n",
    "# df['master_item_chance'] = df['master_probability'].apply(lambda y: [x for x in y if x>0])\n",
    "# df_item_pop_lot = df[['pop_id','field_type','lot_count','lower_item_ids','lower_item_ct', 'lower_item_chance','upper_item_ids','upper_item_ct', 'upper_item_chance','master_item_ids','master_item_ct', 'master_item_chance']]\n",
    "# print(df_item_pop_lot.head(5))\n",
    "# df_item_pop_lot.to_excel('gathering_node_drop_lot.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
